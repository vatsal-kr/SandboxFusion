# SyncSandboxFusion - A synchronous version of SandboxFusion
This fork is intended to run thread pools inside the docker container, as opposed to making API calls in SandboxFusion
Currently we support LiveCodeBench and Code-Contests-Plus in-the-box, but one can trivially extend this to any benchmark with input-output test cases

Add a `secrets.toml` file to this directory with your HuggingFace Personal Access Token
```
HF_KEY = "Your Key Here"
```

## How to use
Here's an example for executing all completions for Code-Contests-Plus generated by Llama-3.1-8B-Instruct in Java
```bash
cd SandboxFusion
echo "Building Sandbox Container"
podman build -t code_sandbox:base --format docker --storage-opt ignore_chown_errors=true -f ./scripts/Dockerfile.base.us .

echo "Running Built Container"
podman run \
        -v /path/to/ccplus/:/root/CCPlus_1x \ # if not downloaded, skip this step and modify sandbox/ccplus.py with the huggingface identifier
        -v /path/to/generated/outputs/base/dir:/root/CCPlus_completions \
        --network host \
        --log-driver json-file \
        --name sandbox_fusion \
        --rm \
        code_sandbox:base \
        bash run_ccplus.sh Llama-3.1-8B-Instruct java
```
## Running all test cases 
The existing scripts run all tests by default. If this is not what you want, modify the `create_SubmitRequest_data` in `sandbox/ccplus.py`
```python
def create_SubmitRequest_data(example):
    example["formatted_cases"] = [
        {
            "id": example["id"],
            "test": [
                {
                    "input": {"stdin": case["input"]},
                    "output": {"stdout": case["output"]},
                }
                for case in example["test_cases"]
            ],
        }
    ]
    return example
```
You will have to handle the thread pool outputs accordingly, but that's about it